{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import np # Torch wrapper for Numpy\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/user/data/amazon_planet'\n",
    "TRAIN_DIR = 'train-jpg'\n",
    "TRAIN_DATA = 'train_v2.csv'\n",
    "TEST_DIR = 'test-jpg'\n",
    "IMG_EXT = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class KaggleAmazonDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, df_csv, img_path, img_ext, transform=None):\n",
    "#         self.mlb = MultiLabelBinarizer()\n",
    "#         self.img_path = img_path\n",
    "#         self.img_ext = img_ext\n",
    "#         self.transform = transform\n",
    "\n",
    "#         self.X_train = df_csv['image_name']\n",
    "#         self.y_train = self.mlb.fit_transform(df_csv['tags'].str.split()).astype(np.float32)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img = Image.open(os.path.join(self.img_path, self.X_train.iloc[index] + self.img_ext))\n",
    "#         img = img.convert('RGB')\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "        \n",
    "#         label = torch.from_numpy(self.y_train[index])\n",
    "#         return img, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KaggleAmazonDatasetInMem(Dataset):\n",
    "\n",
    "    def __init__(self, imgs, labels, transform=None):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        return img, label \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df = pd.read_csv(os.path.join(DATA_DIR, TRAIN_DATA))\n",
    "assert csv_df['image_name'].apply(lambda x: os.path.isfile(os.path.join(DATA_DIR, TRAIN_DIR, x + IMG_EXT))).all(), \\\n",
    "\"Some images referenced in the CSV file were not found\"\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(10, shuffle=True, random_state=1024)\n",
    "\n",
    "# for train, val in kf.split(csv_df):\n",
    "#     split = {'train': train, 'val': val}\n",
    "#     dsets = {x: KaggleAmazonDataset(csv_df.iloc[split[x]], os.path.join(DATA_DIR, TRAIN_DIR),\n",
    "#         IMG_EXT, data_transforms[x]) for x in ['train', 'val']}\n",
    "    \n",
    "#     dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=256, shuffle=True, num_workers=1, pin_memory=True)\n",
    "#         for x in ['train', 'val']}\n",
    "    \n",
    "#     dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "    \n",
    "#     for x in ['train', 'val']:\n",
    "#         print len(dsets[x]) \n",
    "# #     dset_classes = dsets['train'].classes\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36431\n",
      "4048\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "kf = KFold(10, shuffle=True, random_state=1024)\n",
    "\n",
    "\n",
    "for train, val in kf.split(csv_df):\n",
    "    split = {'train': train, 'val': val}\n",
    "    \n",
    "    dsets = {}\n",
    "    \n",
    "    for fold in ['train', 'val']:\n",
    "        data = csv_df.iloc[split[fold]]\n",
    "        x = data['image_name']\n",
    "        imgs = []\n",
    "        for i in x:\n",
    "            img = Image.open(os.path.join(DATA_DIR, TRAIN_DIR, i + IMG_EXT))\n",
    "            img = img.convert('RGB')\n",
    "            imgs.append(img)\n",
    "        y = mlb.fit_transform(data['tags'].str.split()).astype(np.float32)\n",
    "        \n",
    "        dsets[fold] = KaggleAmazonDatasetInMem(imgs, y, data_transforms[fold])\n",
    "    \n",
    "    dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=128, shuffle=True, num_workers=16, pin_memory=True)\n",
    "        for x in ['train', 'val']}\n",
    "    \n",
    "    dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "    \n",
    "    for x in ['train', 'val']:\n",
    "        print len(dsets[x]) \n",
    "#     dset_classes = dsets['train'].classes\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                \n",
    "                print len(inputs)\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), \\\n",
    "                        Variable(labels.cuda())\n",
    "                    print 'using GPU'\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                print 'forward pass'\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                print 'backwards pass'\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc1 = nn.Linear(num_ftrs, 2)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 17)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "LR is set to 0.001\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "    num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
